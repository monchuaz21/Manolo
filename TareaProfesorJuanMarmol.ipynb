{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Equipo:**\n",
    "\n",
    "*Daniel Luizet Castro,\n",
    "Patricia Trujillo Barrios,\n",
    "Manuel Jesús Zamora Monroy*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Redes Neuronales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El siguiente trabajo es sobre un simulador de un problema de clasifiación binario que se encuentra en Playgroud [https://playground.tensorflow.org] en tensorflow en donde a manera visual se puede entender lo que cada parámetro en una red neuronal afecta a la estimación de cada categoría. Para fines del trabajo, el problema que se eligió es el siguiente:\n",
    "\n",
    "* Dataset : Circle\n",
    "* Función de activación: Sigmoide\n",
    "* Split en Train y Test: 50%-50%\n",
    "* Problema: Clasifiación\n",
    "\n",
    "Veremos cómo afecta el Learning Rate, el cual afecta el tamaño del \"paso\" en el gradiente para encontrar un mínimo/máximo local, el número de capas ocultas y la cantidad de features que serán input para el modelo (considerando sólo 2 variables de entrada (x1, x2) y transformaciones a partir de éstas, veremos cómo afecta a la red)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LR: 0.03; Features: 2; Capas: 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Parte1.png](Parte1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con estos parámetros, vemos que se logra estimar correctamente cada una de las categorías, utilizando como input las variables \"brutas\" sin transformación alguna. El error es cercano a 0 y se ve cómo en la segunda capa se \"limitan\" los bordes azules que forman la figura aunque queda como forma triangular."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LR: 0.03; Features: 7; Capas: 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Parte2.jpg](Parte2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aquí se incluyeron transformaciones de las variables x1, x2, tales como elevar al cuadrado, su interación (producto) y funciones trigonométricas (seno(x)). Podemos ver que se logra una forma circular de manera casi perfecta. El error es casi 0 y se ve cómo en la segunda capa se limitan los bordes de los círculos. Itera rápidamente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LR: 0.03; Features: 2; Capas: 2 (1 con 6 neuronas y la última con 4 neuronas)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Parte3.jpg](Parte3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al igual que el primer ejemplo, se llega a una forma triangular, empleando las variables \"brutas\" sin transformación alguna, y aunque se agreguen neuronas a las capas, no se logra la forma circular, aunque el error sea casi 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LR: 0.03; Features: 2; Capas: 3 (1 con 6 neuronas, otra con 4 y la última con 2 neuronas)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Parte4.jpg](Parte4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que aunque se agregue una tercera capa, la forma circular final no es \"perfecta\", aunque el error se aproxime a 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LR: 0.03; Features: 7; Capas: 3 (1 con 6 neuronas, otra con 4 y la última con 2 neuronas)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Parte5.jpg](Parte5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En contraste al ejemplo anterior, agregando transformaciones de las variables x1, x2 podemos ver que llegamos a un círculo casi perfecto, de tal manera que el error se minimiza y se itera rápidamente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LR: 0.03; Features: 2; Capas: 3 (1 con 6 neuronas, otra con 4 y la última con 4 neuronas)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Parte6.jpg](Parte6.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si eliminamos las transformaciones y agregamos más neuronas, no se llega a la forma circular que obtuvimos en el caso anterior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LR: 0.1; Features: 2; Capas: 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Parte7.jpg](Parte7.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aumentando el Learning Rate a 10% y dejando sólo las variables brutas, se llega rápidamente a una correcta clasificación, aunque la forma no sea circular perfecta. El paso que se da en el gradiente (ahora de 0.1) hace que encuentre muy rápido los máximos y mínimos locales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LR: 0.1; Features: 7; Capas: 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Parte8.jpg](Parte8.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Del caso anterior, si agregamos más features, vemos que se llega a una forma circular y de manera rápida."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LR: 0.1; Features: 7; Capas: 3 (1 con 6 neuronas, otra con 4 y otra con 2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Parte9.jpg](Parte9.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agregando más capas y con más neuronas, se llega a una clasifiación muy buena con la forma que queremos y no es tardado dado que el paso que se da en el gradiente es de 0.1 (learning rate) y se ve que se encuentran los máximos y mínimos rápidamente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LR: 0.1; Features: 7; Capas: 3 (1 con 6 neuronas, otra con 4 y otra con 4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Parte10.jpg](Parte10.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este ejemplo agregamos más neuronas a la última capa e igualmente obtuvimos una forma circular casi perfecta, no tarda en lograr esa clasificación y se utilizan todos los features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LR: 0.001; Features: 2; Capas: 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Parte11.jpg](Parte11.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este ejemplo, reducimos el tamaño del paso que se da en el gradiente a 0.001 para encontrar un máximo o mínimo local (\"pasitos\") y tarda demasiado en lograr una clasificación. Y como sólo usamos las variables brutas, no se llega a la forma circular."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LR: 0.001; Features: 7; Capas: 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Parte12.jpg](Parte12.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que tomando todos los features, llegamos a la forma circular aunque la clasificación tarda demasiado tiempo, debido a los pequeños pasos que se da en el gradiente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LR: 0.001; Features: 7; Capas: 3 (1 con 6 neuronas, otra con 4 y otra con 2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Parte13.jpg](Parte13.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se logra una forma circular, se agregan capas y se tarda mucho tiempo en poder lograr una correcta clasificación."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusión"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De las diferentes iteraciones que se hicieron en este ejercicio de clasificación, usando el dataset \"circular\" y bajo un sampling de 50%-50% entre Train y Test, podemos concluir lo siguiente:\n",
    "\n",
    "* Si sólo usamos las variables \"brutas\" (sin transformaciones), no se logra la forma circular \"perfecta\" y se obtiene algo similar a un triángulo aunque el error sea casi 0.\n",
    "* Agregando transformaciones de las variables se llega a una forma circular casi \"perfecta\" y la clasificación sea muy buena y el error casi 0.\n",
    "* El Learning Rate, si lo aumentamos a 0.1 se logra una clasificación muy rápida, en cualquiera de los escenarios (variando capas, incluyendo features, agregando neuronas).\n",
    "* Si disminuimos el Learning Rate a 0.001, se tarda demasiado tiempo en lograr una clasificación, en cualquiera de los escenarios.\n",
    "\n",
    "De esta forma, podemos ver cómo influye el Learning Rate en el gradiente, debido al tamaño del paso que se da hacia cierta dirección para poder encontrar un máximo o mínimo local de la función.\n",
    "\n",
    "El número de variables que se usan como input influye en la clasifiación, pero agregando transformaciones de éstas, la clasificación es mejor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aplicación de lo visto en clase en el trabajo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Independientemente de las Redes Neuronales, hay un tema de los vistos en el módulo de ML con Python que nos es de mucha utilidad.\n",
    "\n",
    "Cuando presentamos un modelo y el resultado final a \"negocio\", siempre nos hacen la pregunta ¿Qué variable es la que influye en el cliente?. Como hemos empleado modelos de Machine Learning, la respuesta siempre es difícil, pues es una interacción de decenas de variables para poder identificar a aquellos clientes con potencial a \"algo\", ya sea que se vuelvan clientes de \"alto valor\", con \"alta probabilidad de attrition\", que el \"attrition\" sea \"silencioso\" (es decir, dejan de usar un producto, mas no cancelan el producto).\n",
    "\n",
    "Ejemplo: Cuando un cliente baja su facturación pero no cancela la tarjeta\n",
    "\n",
    "Pregunta: ¿Por qué? ¿Es la línea de crédito? ¿Es la tasa?\n",
    "\n",
    "Con lo que vimos en clase, el paquete ICE nos puede ayudar a responder esa pregunta. Podemos ver las Partial Dependence Plots de cada variable y de cómo a diferentes valores se ve afectada la población, de tal manera que podemos ver cuál es la variable que, por caso, es la que más afecta a cierto cliente. Gráficamente sería difícil de apreciar (a diferencia de lo visto en clase) dado que son ~5 millones de tarjetahabientes, pero podemos utilizar un localizador para que ubique cuáles clientes sí son sensibles a cada una de las variables.\n",
    "\n",
    "Ejemplo: En riesgo de originación\n",
    "\n",
    "Pregunta: ¿Por qué aceptas o rechazas una tarjeta a un cliente?\n",
    "\n",
    "Con lo que vimos en LIME podemos hacer un análisis por caso para ver qué variable fue la que más influyó en el proceso de dictaminación de otorgar o no una tarjeta a un cliente. De esta forma se le puede explicar al cliente (si lo solicita) la razón de rechazo o de aceptación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
